== Line Tokenizer
This modules consumes an object stream as created by https://github.com/darlenya/stream-line-parser[stream-line-parser] and splits the line into tokens.
The emitted line objects have the following form:

.Line object example
[source,json]
----
{
  "lineNumber": 1,
  "data": "['any', 'line', 'data']"
}
----

This module was inspired (mostly copied from ''csv-parser'' https://github.com/mafintosh/csv-parser)

=== Install
[source,bash]
----
$ npm install stream-line-tokenizer-csv
----


=== Usage

.Options for the parser
[source,js]
----
{
  "separator_list" : [',', ';'],   // <1>
  "quote_char" : '"',              // <2>
  "use_quotes" : true,             // <3>
  "trim" : true                    // <4>
}
----
<1> (Optional, default=[",", ";", "\t"]). A list of possible separators. The first one found in the first line will
be taken as separator for the whole stream.
<2> (Optional, default is '"' ). The character used to quote strings
<3> (Optional, default is true). If set to false, the quote characters will be taken as normal chars.
<4> (Optional, default is true). If set to true, the field values will be trimmed. Remove leading and trailing
white space characters. If the field was set in quotes, then the spaces will be kept.



.Usage example
[source,js]
----
const fs = require('fs');
const lp = require('stream-line-parser');
const tk = require('stream-line-tokenizer-csv');

let parser = lp({
  "allow_new_line_in_cell" : true,
	"line_separator": "\n",
  "quote_char" : '"',
  "skip_empty_lines" : true
});

let tokenizer = tk({
  "separator_list" : [',', ';'],
  "quote_char" : '"',
  "use_quotes" : true,
  "trim" : true
  });

fs.createReadStream('filename.csv').pipe(parser).pipe(tokenizer);

----

This will read the file 'filename.csv'. The stream will be piped to the parser which
will split the stream in to objects. The parser emits an object stream. This object
stream will then be piped to the line tokenizer.
